[{"authors":null,"categories":null,"content":"I obtained my PhD in December 2016 from the University of Saint-Etienne, France. During my thesis I mainly studied Metric Learning, more precisely it was about Learning Metrics with a Controlled Behaviour. I did it under the supervision of Amaury Habrard in the Laboratoire Hubert Curien.\nSince April 2017 I work as a post-doc researcher in the Statistical Learning Theory research group led by Ulrike von Luxburg. This group is part of both the Eberhard Karls Universität Tübingen and the Max Planck Institute for Intelligent Systems. I study the problem of learning from ordinal data, generally termed as Comparison-based Learning.\n","date":1549285763,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1549285763,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://mperrot.github.io/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"I obtained my PhD in December 2016 from the University of Saint-Etienne, France. During my thesis I mainly studied Metric Learning, more precisely it was about Learning Metrics with a Controlled Behaviour. I did it under the supervision of Amaury Habrard in the Laboratoire Hubert Curien.\nSince April 2017 I work as a post-doc researcher in the Statistical Learning Theory research group led by Ulrike von Luxburg. This group is part of both the Eberhard Karls Universität Tübingen and the Max Planck Institute for Intelligent Systems.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"https://mperrot.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Debarghya Ghoshdastidar","Michaël Perrot","Ulrike von Luxburg"],"categories":null,"content":"","date":1541026800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"05aaaf5f28bec62f67a6f105191774cb","permalink":"https://mperrot.github.io/publication/comparison-based-hierarchical-clustering/","publishdate":"2018-11-01T00:00:00+01:00","relpermalink":"/publication/comparison-based-hierarchical-clustering/","section":"publication","summary":"We address the classical problem of hierarchical clustering, but in a framework where one does not have access to a representation of the objects or their pairwise similarities. Instead we assume that only a set of comparisons between objects are available in terms of statements of the form \"objects $i$ and $j$ are more similar than objects $k$ and $l$.'' Such a scenario is commonly encountered in crowdsourcing applications. The focus of this work is to develop comparison-based hierarchical clustering algorithms that do not rely on the principles of ordinal embedding. We propose comparison-based variants of average linkage clustering. We provide statistical guarantees for the proposed methods under a planted partition model for hierarchical clustering. We also empirically demonstrate the performance of the proposed methods on several datasets.","tags":["Comparison-based learning","Hierarchical clustering","Learning theory"],"title":"Foundations of Comparison-Based Hierarchical Clustering","type":"publication"},{"authors":["Michaël Perrot","Ulrike von Luxburg"],"categories":null,"content":"","date":1538344800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"dcc9c3230529ba15586b67eb0bc48de6","permalink":"https://mperrot.github.io/publication/boosting-comparison-based-learning/","publishdate":"2018-10-01T00:00:00+02:00","relpermalink":"/publication/boosting-comparison-based-learning/","section":"publication","summary":"We consider the problem of classification in a comparison-based setting: given a set of objects, we only have access to triplet comparisons of the form \"object $x\\_i$ is closer to object $x\\_j$ than to object $x\\_k$.'' In this paper we introduce TripletBoost, a new method that can learn a classifier just from such triplet comparisons. The main idea is to aggregate the triplets information into weak classifiers, which can subsequently be boosted to a strong classifier. Our method has two main advantages: (i) it is applicable to data from any metric space, and (ii) it can deal with large scale problems using only passively obtained and noisy triplets. We derive theoretical generalization guarantees and a lower bound on the number of necessary triplets, and we empirically show that our method is both competitive with state of the art approaches and resistant to noise.","tags":["Comparison-based learning","Boosting"],"title":"Boosting for Comparison-Based Learning","type":"publication"},{"authors":["Michaël Perrot","Nicolas Courty","Rémi Flamary","Amaury Habrard"],"categories":null,"content":"","date":1480546800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"9dc7810953ba3ec504afd0761837ec01","permalink":"https://mperrot.github.io/publication/mapping-estimation-optimal-transport/","publishdate":"2016-12-01T00:00:00+01:00","relpermalink":"/publication/mapping-estimation-optimal-transport/","section":"publication","summary":"We are interested in the computation of the transport map of an Optimal Transport problem. Most of the computational approaches of Optimal Transport use the Kantorovich relaxation of the problem to learn a probabilistic coupling $\\gamma$ but do not address the problem of learning the underlying transport map $T$ linked to the original Monge problem. Consequently, it lowers the potential usage of such methods in contexts where out-of-samples computations are mandatory. In this paper we propose a new way to jointly learn the coupling and an approximation of the transport map. We use a jointly convex formulation which can be efficiently optimized. Additionally, jointly learning the coupling and the transport map allows to smooth the result of the Optimal Transport and generalize it to out-of-samples examples. Empirically, we show the interest and the relevance of our method in two tasks: domain adaptation and image editing.","tags":["Optimal Transport"],"title":"Mapping Estimation for Discrete Optimal Transport","type":"publication"},{"authors":["Michaël Perrot","Amaury Habrard"],"categories":null,"content":"","date":1448924400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"7fc81fb77afc214bd2c663db1497c603","permalink":"https://mperrot.github.io/publication/regressive-virtual-metric-learning/","publishdate":"2015-12-01T00:00:00+01:00","relpermalink":"/publication/regressive-virtual-metric-learning/","section":"publication","summary":"We are interested in supervised metric learning of Mahalanobis like distances. Existing approaches mainly focus on learning a new distance using similarity and dissimilarity constraints between examples. In this paper, instead of bringing closer examples of the same class and pushing far away examples of different classes we propose to move the examples with respect to virtual points. Hence, each example is brought closer to a a priori defined virtual point reducing the number of constraints to satisfy. We show that our approach admits a closed form solution which can be kernelized. We provide a theoretical analysis showing the consistency of the approach and establishing some links with other classical metric learning methods. Furthermore we propose an efficient solution to the difficult problem of selecting virtual points based in part on recent works in optimal transport. Lastly, we evaluate our approach on several state of the art datasets.","tags":["Metric learning"],"title":"Regressive Virtual Metric Learning","type":"publication"},{"authors":["Michaël Perrot","Amaury Habrard"],"categories":null,"content":" ","date":1435701600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"244ae83dfa022e39081fb80ee97eaabc","permalink":"https://mperrot.github.io/publication/metric-hypothesis-transfer-learning/","publishdate":"2015-07-01T00:00:00+02:00","relpermalink":"/publication/metric-hypothesis-transfer-learning/","section":"publication","summary":"We consider the problem of transferring some a priori knowledge in the context of supervised metric learning approaches. While this setting has been successfully applied in some empirical contexts, no theoretical evidence exists to justify this approach. In this paper, we provide a theoretical justification based on the notion of algorithmic stability adapted to the regularized metric learning setting. We propose an on-average-replace-two-stability model allowing us to prove fast generalization rates when an auxiliary source metric is used to bias the regularizer. Moreover, we prove a consistency result from which we show the interest of considering biased weighted regularized formulations and we provide a solution to estimate the associated weight. We also present some experiments illustrating the interest of the approach in standard metric learning tasks and in a transfer learning problem where few labelled data are available.","tags":["Metric learning","Learning Theory"],"title":"A Theoretical Analysis of Metric Hypothesis Transfer Learning","type":"publication"},{"authors":["Michaël Perrot","Amaury Habrard","Damien Muselet","Marc Sebban"],"categories":null,"content":" ","date":1409522400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"a1745b07526f947ef1339389e1c9d0c0","permalink":"https://mperrot.github.io/publication/perceptual-color-learning/","publishdate":"2014-09-01T00:00:00+02:00","relpermalink":"/publication/perceptual-color-learning/","section":"publication","summary":"Having perceptual differences between scene colors is key in many computer vision applications such as image segmentation or visual salient region detection. Nevertheless, most of the times, we only have access to the rendered image colors, without any means to go back to the true scene colors. The main existing approaches propose either to compute a perceptual distance between the rendered image colors, or to estimate the scene colors from the rendered image colors and then to evaluate perceptual distances. However the first approach provides distances that can be far from the scene color differences while the second requires the knowledge of the acquisition conditions that are unavailable for most of the applications. In this paper, we design a new local Mahalanobis-like metric learning algorithm that aims at approximating a perceptual scene color difference that is invariant to the acquisition conditions and computed only from rendered image colors. Using the theoretical framework of uniform stability, we provide consistency guarantees on the learned model. Moreover, our experimental evaluation shows its great ability (i) to generalize to new colors and devices and (ii) to deal with segmentation tasks.","tags":["Metric learning","Perceptual Color Differences"],"title":"Modeling Perceptual Color Differences by Local Metric Learning","type":"publication"},{"authors":["Leonor Becerra-Bonache","Élisa Fromont","Amaury Habrard","Michaël Perrot","Marc Sebban"],"categories":null,"content":"","date":1346450400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549285948,"objectID":"eb9341f94d9c4c1cfc5715d0cbc6d879","permalink":"https://mperrot.github.io/publication/speeding-up-syntactic-learning/","publishdate":"2012-09-01T00:00:00+02:00","relpermalink":"/publication/speeding-up-syntactic-learning/","section":"publication","summary":"It has been shown in (Angluin and Becerra-Bonache, 2010, 2011) that interactions between a learner and a teacher can help language learning. In this paper, we make use of additional contextual information in a pairwise-based generative approach aiming at learning (situation,sentence)-pair-hidden markov models. We show that this allows a significant speed-up of the convergence of the syntactic learning. We apply our model on a toy natural language task in Spanish dealing with geometric objects.","tags":["Language learning"],"title":"Speeding Up Syntactic Learning using Contextual Information","type":"publication"}]